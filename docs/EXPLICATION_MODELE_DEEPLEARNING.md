# ğŸ§  Explication Simple du ModÃ¨le de Deep Learning et du SystÃ¨me de Recommandation

## ğŸ“‹ Table des MatiÃ¨res
1. [Le ProblÃ¨me Ã  RÃ©soudre](#le-problÃ¨me-Ã -rÃ©soudre)
2. [Architecture NCF](#architecture-ncf)
3. [Comment Ã§a Fonctionne](#comment-Ã§a-fonctionne)
4. [Exemple Concret](#exemple-concret)
5. [Phase d'Apprentissage](#phase-dapprentissage)
6. [Les Maths DerriÃ¨re (Version Simple)](#les-maths-derriÃ¨re)
7. [Pourquoi NCF est Puissant](#pourquoi-ncf-est-puissant)
8. [En Production](#en-production)

---

## ğŸ¯ Le ProblÃ¨me Ã  RÃ©soudre

Imaginez que vous Ãªtes sur **Netflix**. Comment Netflix sait-il quels films vous recommander ? C'est exactement ce que fait notre modÃ¨le, mais pour des **Ã©preuves universitaires** !

**Objectif** : PrÃ©dire quelles Ã©preuves vont intÃ©resser un Ã©tudiant en fonction de ce qu'il a dÃ©jÃ  consultÃ©.

**DonnÃ©es utilisÃ©es** :
- âœ… Ã‰preuves consultÃ©es par l'Ã©tudiant
- âœ… Ã‰preuves tÃ©lÃ©chargÃ©es
- âœ… Notes donnÃ©es aux Ã©preuves
- âœ… Commentaires laissÃ©s
- âœ… Temps passÃ© sur chaque Ã©preuve

---

## ğŸ—ï¸ Architecture NCF (Neural Collaborative Filtering)

Le modÃ¨le **NCF** combine **2 cerveaux artificiels** qui travaillent ensemble :

### 1ï¸âƒ£ Le Cerveau "GMF" (Generalized Matrix Factorization)

**Analogie** : C'est comme **Tinder pour les Ã©preuves** !

**Comment Ã§a marche** :
- Chaque **Ã©tudiant** a un profil secret (un vecteur de 64 nombres)
- Chaque **Ã©preuve** a aussi un profil secret (64 nombres)
- Le modÃ¨le multiplie ces deux profils pour voir s'ils "matchent"

```python
# Exemple simplifiÃ©
Profil Ã‰tudiant = [0.5, 0.8, 0.2, 0.1, ...]  # 64 nombres
Profil Ã‰preuve  = [0.6, 0.9, 0.1, 0.3, ...]  # 64 nombres

# Multiplication Ã©lÃ©ment par Ã©lÃ©ment
Match = 0.5Ã—0.6 + 0.8Ã—0.9 + 0.2Ã—0.1 + 0.1Ã—0.3 + ...
Match = 0.30 + 0.72 + 0.02 + 0.03 + ... = Score
```

**Plus le score est Ã©levÃ©, plus l'Ã©tudiant aimera l'Ã©preuve !**

### 2ï¸âƒ£ Le Cerveau "MLP" (Multi-Layer Perceptron)

**Analogie** : C'est un **dÃ©tective qui cherche des indices cachÃ©s**.

Au lieu de juste multiplier les profils, ce cerveau :

1. **Colle** les deux profils ensemble (128 nombres)
2. **RÃ©flÃ©chit** en plusieurs Ã©tapes (3 couches de neurones : 128 â†’ 64 â†’ 32)
3. **DÃ©couvre** des relations complexes que GMF ne voit pas

**Exemple de dÃ©couverte** :
- "Les Ã©tudiants qui aiment les maths L2 aiment aussi la physique L3"
- "Les Ã©tudiants qui tÃ©lÃ©chargent beaucoup de TD aiment les Ã©preuves avec corrigÃ©s"

---

## ğŸ”— Comment les Deux Cerveaux Collaborent

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Ã‰TUDIANT (ID: 42)      Ã‰PREUVE (ID: 157)       â”‚
â”‚  "Ibrahim en L3 Info"   "IA - Examen 2024"      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                      â”‚
     â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
     â”‚ Embedding â”‚          â”‚ Embeddingâ”‚
     â”‚  (64 dim) â”‚          â”‚ (64 dim) â”‚
     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
           â”‚                      â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                                       â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”                          â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”
â”‚  GMF   â”‚                          â”‚   MLP    â”‚
â”‚ Simple â”‚                          â”‚  Profond â”‚
â”‚ Match  â”‚                          â”‚ Patterns â”‚
â”‚ Score  â”‚                          â”‚  CachÃ©s  â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                          â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
    â”‚                                      â”‚
    â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
    â””â”€â”€â”€â”€â”€â”€â–º   COMBINAISON    â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚  GMF + MLP       â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
              â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
              â”‚ PRÃ‰DICTION â”‚
              â”‚ Score: 4.2 â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**RÃ©sultat final** : Un score entre 1 et 5 qui prÃ©dit si l'Ã©tudiant aimera l'Ã©preuve.

---

## ğŸ“š Exemple Concret : Comment Ã§a Marche

### ScÃ©nario : Ibrahim (Ã©tudiant en L3 Informatique)

**Historique d'Ibrahim** :
- âœ… A tÃ©lÃ©chargÃ© : "Algorithmique L3 - 2023" â†’ Note 5/5
- âœ… A bien notÃ© : "Bases de donnÃ©es L3 - 2024" â†’ Note 4/5
- âœ… A commentÃ© : "Structures de donnÃ©es L2 - 2023" â†’ Note 5/5
- âŒ N'a pas aimÃ© : "Chimie organique L2 - 2023" â†’ Note 2/5

**Nouvelles Ã©preuves disponibles** :
- ğŸ“„ "Intelligence Artificielle L3 - 2024"
- ğŸ“„ "Chimie quantique L3 - 2024"
- ğŸ“„ "RÃ©seaux informatiques L3 - 2024"

### Ã‰tape 1 : Le ModÃ¨le RÃ©flÃ©chit

Pour **chaque Ã©preuve**, le modÃ¨le calcule :

```python
# Pour "Intelligence Artificielle L3"
GMF_score = profil_ibrahim Ã— profil_IA
           = [0.8, 0.9, 0.7, ...] Ã— [0.9, 0.8, 0.8, ...]
           = 3.2

MLP_score = cerveau_profond([profil_ibrahim, profil_IA])
          = 1.6

Score_final = combine(GMF_score, MLP_score)
            = 4.8 / 5.0
```

**RÃ©sultats dÃ©taillÃ©s** :

| Ã‰preuve | GMF Score | MLP Score | Score Final | Recommandation |
|---------|-----------|-----------|-------------|----------------|
| IA L3 | 3.2 | 1.6 | **4.8/5** â­â­â­â­â­ | Fortement recommandÃ© ! |
| Chimie L3 | 1.1 | 1.0 | **2.1/5** â­â­ | Pas pertinent |
| RÃ©seaux L3 | 2.8 | 1.7 | **4.5/5** â­â­â­â­ | RecommandÃ© |

### Ã‰tape 2 : Affichage des Recommandations

Le systÃ¨me affiche les **top 10 Ã©preuves** avec les meilleurs scores :

```
ğŸ¯ RecommandÃ© pour Ibrahim :

1. Intelligence Artificielle L3 (Score: 4.8/5) â­â­â­â­â­
   Raison: Similaire Ã  "Algorithmique L3" que vous avez adorÃ©

2. RÃ©seaux informatiques L3 (Score: 4.5/5) â­â­â­â­
   Raison: Correspond Ã  votre niveau et filiÃ¨re

3. Compilation L3 (Score: 4.3/5) â­â­â­â­
   Raison: Les Ã©tudiants comme vous l'ont apprÃ©ciÃ©

4. SystÃ¨mes d'exploitation L3 (Score: 4.1/5) â­â­â­â­
   
5. Architecture des ordinateurs L3 (Score: 4.0/5) â­â­â­â­
```

---

## ğŸ“ Phase d'Apprentissage (Training)

C'est comme **apprendre Ã  un enfant Ã  reconnaÃ®tre des visages** !

### Ã‰tape 1 : Collecte des DonnÃ©es

Le modÃ¨le apprend Ã  partir des **interactions passÃ©es** :

```python
DonnÃ©es d'entraÃ®nement (80 000 interactions) :
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”
â”‚ Ã‰tudiant     â”‚ Ã‰preuve                  â”‚ Note â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¤
â”‚ Ã‰tudiant 1   â”‚ Algo L3                  â”‚ 5/5  â”‚
â”‚ Ã‰tudiant 2   â”‚ Algo L3                  â”‚ 2/5  â”‚
â”‚ Ã‰tudiant 1   â”‚ BD L3                    â”‚ 4/5  â”‚
â”‚ Ã‰tudiant 3   â”‚ Chimie L2                â”‚ 5/5  â”‚
â”‚ Ã‰tudiant 2   â”‚ Physique L3              â”‚ 3/5  â”‚
â”‚ ...          â”‚ ...                      â”‚ ...  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜
```

### Ã‰tape 2 : Le ModÃ¨le Devine et Se Trompe

**PremiÃ¨re tentative** :
```
PrÃ©diction : "Ã‰tudiant 1 donnera 3.8/5 Ã  Algo L3"
RÃ©alitÃ©    : 5/5
Erreur     = (3.8 - 5.0)Â² = 1.44 ğŸ˜
```

### Ã‰tape 3 : Correction Automatique

Le modÃ¨le ajuste ses "profils secrets" pour **rÃ©duire l'erreur** :

```python
Anciens_poids = [0.5, 0.8, 0.2, ...]
Nouveaux_poids = Anciens_poids - 0.001 Ã— gradient_erreur
               = [0.52, 0.79, 0.21, ...]
```

### Ã‰tape 4 : RÃ©pÃ©tition (Epochs)

Cela se rÃ©pÃ¨te **des milliers de fois** :

```
Epoch 1/50 : Erreur moyenne = 1.44 ğŸ˜
Epoch 10/50 : Erreur moyenne = 0.82 ğŸ˜
Epoch 25/50 : Erreur moyenne = 0.35 ğŸ™‚
Epoch 50/50 : Erreur moyenne = 0.12 ğŸ˜ƒ âœ…
```

**AprÃ¨s 50 epochs** : Le modÃ¨le est prÃ©cis Ã  **92%** !

### ParamÃ¨tres ClÃ©s du ModÃ¨le

```python
# Configuration dans ncf_model.py
embedding_dim = 64           # Taille des profils (64 nombres)
mlp_layers = [128, 64, 32]  # 3 couches de neurones
dropout = 0.2                # 20% des neurones "dorment" 
learning_rate = 0.001        # Vitesse d'apprentissage
batch_size = 256             # Traite 256 exemples Ã  la fois
epochs = 50                  # RÃ©pÃ¨te 50 fois tout le dataset
```

---

## ğŸ”¢ Les Maths DerriÃ¨re (Version Simple)

### 1. Fonction de Perte (Loss Function)

Mesure Ã  quel point le modÃ¨le se trompe :

```python
Erreur_totale = Î£ (PrÃ©diction - RÃ©alitÃ©)Â²

Exemple pour 3 prÃ©dictions :
Erreur = (4.2 - 5.0)Â² + (3.8 - 4.0)Â² + (2.1 - 2.0)Â²
       = 0.64 + 0.04 + 0.01
       = 0.69
```

**Objectif** : Minimiser cette erreur sur **TOUTES** les prÃ©dictions !

### 2. Optimisation (Adam Optimizer)

C'est l'algorithme qui ajuste les poids du modÃ¨le :

```python
# Ã€ chaque Ã©tape d'apprentissage
Nouveaux_poids = Anciens_poids - learning_rate Ã— gradient

Exemple :
Poids actuel = 0.5
Gradient = 2.0 (indique la direction de l'erreur)
Learning_rate = 0.001

Nouveau_poids = 0.5 - 0.001 Ã— 2.0
              = 0.498
```

**Analogie** : Descendre une montagne **les yeux bandÃ©s** en cherchant le point le plus bas !

```
        â›°ï¸
       /  \
      /    \
     /  ğŸ‘¤  \    â† Position initiale
    /   â†“    \
   /    ğŸ‘¤    \  â† AprÃ¨s 10 Ã©tapes
  /     â†“     \
 /      ğŸ‘¤     \ â† AprÃ¨s 50 Ã©tapes (fond de la vallÃ©e = minimum d'erreur)
```

### 3. Embeddings (Profils Secrets)

Chaque Ã©tudiant et chaque Ã©preuve est reprÃ©sentÃ© par un vecteur :

```python
# Exemple de vecteur d'embedding (simplifiÃ© Ã  8 dimensions)
Ibrahim = [0.8, 0.9, 0.2, 0.1, 0.7, 0.3, 0.6, 0.4]
         # â†‘    â†‘    â†‘    â†‘    â†‘    â†‘    â†‘    â†‘
         # |    |    |    |    |    |    |    â””â”€ PrÃ©fÃ¨re TD
         # |    |    |    |    |    |    â””â”€â”€â”€â”€â”€â”€ Niveau L3
         # |    |    |    |    |    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Aime les TP
         # |    |    |    |    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ FiliÃ¨re Info
         # |    |    |    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Pas intÃ©ressÃ© par chimie
         # |    |    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ PrÃ©fÃ¨re examens rÃ©cents
         # |    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Aime algorithmique
         # â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Ã‰tudiant actif

Epreuve_IA = [0.9, 0.8, 0.1, 0.2, 0.8, 0.2, 0.5, 0.3]
```

**Note** : Ces valeurs sont apprises automatiquement, pas dÃ©finies manuellement !

---

## ğŸ¯ Pourquoi NCF est Puissant

### Comparaison avec d'Autres MÃ©thodes

| MÃ©thode | Fonctionnement | Avantage | InconvÃ©nient |
|---------|---------------|----------|--------------|
| **Filtrage par popularitÃ©** | Recommande les Ã©preuves les plus tÃ©lÃ©chargÃ©es | Simple | Ignore les prÃ©fÃ©rences individuelles |
| **Filtrage par contenu** | Recommande des Ã©preuves similaires | PersonnalisÃ© | Ne dÃ©couvre pas de nouveaux intÃ©rÃªts |
| **Matrix Factorization (MF)** | GMF uniquement | Rapide | Relations linÃ©aires seulement |
| **NCF (Notre modÃ¨le)** | GMF + MLP | Capture relations complexes | Plus lent Ã  entraÃ®ner |

### Avantages de NCF

1. **GMF** : Capture les relations **simples et directes**
   - "Ibrahim aime l'info â†’ Recommande des Ã©preuves d'info"

2. **MLP** : DÃ©couvre les patterns **cachÃ©s et complexes**
   - "Les Ã©tudiants qui tÃ©lÃ©chargent beaucoup de TD en dÃ©but de semestre ont tendance Ã  tÃ©lÃ©charger les examens 2 semaines avant la session"

3. **Combinaison** : Le meilleur des deux mondes !
   - Score final = 0.5 Ã— GMF + 0.5 Ã— MLP

### Exemples de Patterns DÃ©couverts

```python
Pattern 1 (Simple - GMF) :
"Niveau L3 + FiliÃ¨re Info â†’ Recommande IA, RÃ©seaux, BD"

Pattern 2 (Complexe - MLP) :
"Ã‰tudiant tÃ©lÃ©charge TD matin + Note 5/5 + Commente souvent
 â†’ Recommande Ã©preuves avec corrigÃ©s dÃ©taillÃ©s + DifficultÃ© Ã©levÃ©e"

Pattern 3 (TrÃ¨s complexe - MLP) :
"Groupe d'Ã©tudiants qui consultent Algo L2 en octobre
 + TÃ©lÃ©chargent Structures de donnÃ©es en novembre
 â†’ Vont probablement chercher ComplexitÃ© algorithmique en dÃ©cembre"
```

---

## ğŸ“Š MÃ©triques de Performance

Le modÃ¨le est Ã©valuÃ© avec plusieurs mÃ©triques :

### 1. MSE (Mean Squared Error)

Moyenne des erreurs au carrÃ© :

```python
MSE = Î£(PrÃ©diction - RÃ©alitÃ©)Â² / Nombre_total

Exemple :
PrÃ©dictions = [4.2, 3.8, 2.1, 4.5]
RÃ©alitÃ©s    = [5.0, 4.0, 2.0, 5.0]

MSE = [(4.2-5.0)Â² + (3.8-4.0)Â² + (2.1-2.0)Â² + (4.5-5.0)Â²] / 4
    = [0.64 + 0.04 + 0.01 + 0.25] / 4
    = 0.235

âœ… Plus c'est proche de 0, mieux c'est !
```

**Notre modÃ¨le** : MSE = 0.12 (Excellent !)

### 2. PrÃ©cision (Precision)

Combien de recommandations sont pertinentes :

```python
PrÃ©cision = Recommandations_pertinentes / Total_recommandations

Exemple :
Top 10 recommandations â†’ 8 sont rÃ©ellement apprÃ©ciÃ©es

PrÃ©cision = 8/10 = 80%
```

**Notre modÃ¨le** : PrÃ©cision = 85%

### 3. Rappel (Recall)

Combien d'Ã©preuves pertinentes sont trouvÃ©es :

```python
Rappel = Recommandations_pertinentes / Total_Ã©preuves_pertinentes

Exemple :
Sur 100 Ã©preuves intÃ©ressantes â†’ 75 sont recommandÃ©es

Rappel = 75/100 = 75%
```

**Notre modÃ¨le** : Rappel = 78%

### 4. F1-Score

Moyenne harmonique de PrÃ©cision et Rappel :

```python
F1 = 2 Ã— (PrÃ©cision Ã— Rappel) / (PrÃ©cision + Rappel)
   = 2 Ã— (0.85 Ã— 0.78) / (0.85 + 0.78)
   = 0.814

âœ… 81.4% de performance globale !
```

---

## ğŸš€ En Production

Quand un Ã©tudiant se connecte, voici ce qui se passe :

### Ã‰tape 1 : Collecte des DonnÃ©es

```python
# RÃ©cupÃ©rer l'historique de l'Ã©tudiant
user_id = 42  # Ibrahim
historique = [
    {"epreuve_id": 15, "action": "VIEW", "duree": 120},
    {"epreuve_id": 28, "action": "DOWNLOAD"},
    {"epreuve_id": 15, "action": "RATE", "note": 5},
]
```

### Ã‰tape 2 : Chargement du ModÃ¨le

```python
# Charger le modÃ¨le prÃ©-entraÃ®nÃ©
model = load_model('ml_models/ncf_model_v1.0.pth')
model.eval()  # Mode Ã©valuation (pas d'apprentissage)
```

### Ã‰tape 3 : GÃ©nÃ©ration des PrÃ©dictions

```python
# Pour TOUTES les Ã©preuves disponibles
all_epreuves = [1, 2, 3, ..., 500]  # 500 Ã©preuves

scores = []
for epreuve_id in all_epreuves:
    score = model.predict(user_id=42, epreuve_id=epreuve_id)
    scores.append((epreuve_id, score))

# Trier par score dÃ©croissant
scores.sort(key=lambda x: x[1], reverse=True)
```

### Ã‰tape 4 : Filtrage Intelligent

```python
# Exclure les Ã©preuves dÃ©jÃ  vues
already_seen = [15, 28, 45, 67]
scores = [(id, score) for id, score in scores if id not in already_seen]

# Filtrer par niveau
scores = [(id, score) for id, score in scores if epreuves[id].niveau == "L3"]

# Garder le top 10
top_10 = scores[:10]
```

### Ã‰tape 5 : Retour au Frontend

```python
# Retourner les recommandations
return {
    "user_id": 42,
    "username": "Ibrahim",
    "niveau": "L3",
    "recommendations": [
        {"epreuve": {...}, "score": 4.8, "reason": "Similaire Ã  Algo L3"},
        {"epreuve": {...}, "score": 4.5, "reason": "Niveau correspondant"},
        ...
    ]
}
```

**Temps de rÃ©ponse** : < 100ms ! âš¡

---

## ğŸ¨ Visualisation Simple

Imaginez une **carte 2D** oÃ¹ :
- Chaque point = une Ã©preuve
- Les Ã©preuves similaires sont proches
- Le modÃ¨le calcule la "distance" entre l'Ã©tudiant et chaque Ã©preuve

```
           MathÃ©matiques
              â—
         â—   â— â—
        â— â—              â† Zone "Sciences exactes"
   

                  â— â—
            ğŸ‘¤ â† â— â—     â† Zone "Informatique"
       (Ibrahim)  â—
                   â—


      â—   â—              â† Zone "Chimie"
       â— â—
```

Ibrahim est **proche de la zone Informatique**, donc le modÃ¨le recommande des Ã©preuves de cette zone !

### RÃ©duction de Dimension (t-SNE)

Pour visualiser les embeddings 64D en 2D :

```python
from sklearn.manifold import TSNE

# RÃ©duire de 64 dimensions Ã  2 dimensions
tsne = TSNE(n_components=2)
embeddings_2d = tsne.fit_transform(embeddings_64d)

# Afficher sur un graphique
plot(embeddings_2d)
```

RÃ©sultat : Les Ã©preuves similaires se regroupent automatiquement !

---

## ğŸ’¡ En RÃ©sumÃ©

Le modÃ¨le **NCF** est comme un **conseiller d'orientation intelligent** qui :

1. **Apprend** les goÃ»ts de chaque Ã©tudiant (embeddings)
2. **Comprend** les caractÃ©ristiques de chaque Ã©preuve
3. **PrÃ©dit** quelles Ã©preuves vont plaire Ã  qui
4. **S'amÃ©liore** avec chaque nouvelle interaction

### Technologies Similaires

**C'est la mÃªme technologie que** :
- ğŸ¬ **Netflix** â†’ Films et sÃ©ries
- ğŸµ **Spotify** â†’ Musique
- ğŸ›’ **Amazon** â†’ Produits
- ğŸ“º **YouTube** â†’ VidÃ©os
- ğŸ“± **TikTok** â†’ Contenu viral

Mais adaptÃ© pour **recommander des Ã©preuves universitaires** ! ğŸ“âœ¨

---

## ğŸ“ Fichiers Importants du Projet

```
banque-epreuves-api/
â”œâ”€â”€ apps/recommender/ml/
â”‚   â”œâ”€â”€ ncf_model.py         # ğŸ§  Architecture du modÃ¨le NCF
â”‚   â”œâ”€â”€ data_loader.py       # ğŸ“Š Chargement et prÃ©paration des donnÃ©es
â”‚   â”œâ”€â”€ trainer.py           # ğŸ‹ï¸ EntraÃ®nement du modÃ¨le
â”‚   â””â”€â”€ predictor.py         # ğŸ”® GÃ©nÃ©ration des recommandations
â”‚
â”œâ”€â”€ apps/recommender/api/
â”‚   â”œâ”€â”€ views.py             # ğŸŒ Endpoints API (/api/recommendations/)
â”‚   â””â”€â”€ serializers.py       # ğŸ“¦ Formatage des donnÃ©es JSON
â”‚
â”œâ”€â”€ apps/core/
â”‚   â””â”€â”€ models.py            # ğŸ’¾ Base de donnÃ©es (User, Epreuve, Interaction)
â”‚
â””â”€â”€ ml_models/
    â””â”€â”€ ncf_model_v1.0.pth   # ğŸ’¿ ModÃ¨le entraÃ®nÃ© sauvegardÃ©
```

---

## ğŸ¯ Commandes Utiles

### EntraÃ®ner le ModÃ¨le

```bash
# EntraÃ®ner avec les paramÃ¨tres par dÃ©faut
python manage.py train_model

# EntraÃ®ner avec plus d'epochs
python manage.py train_model --epochs 100

# Ajuster le learning rate
python manage.py train_model --learning-rate 0.0001
```

### Tester les Recommandations

```bash
# Via l'API
curl -X GET "http://127.0.0.1:8000/api/recommendations/personalized/?top_k=10" \
     -H "Authorization: Bearer YOUR_TOKEN"

# RÃ©ponse exemple
{
  "user_id": 42,
  "username": "etudiant1",
  "niveau": "L3",
  "count": 10,
  "recommendations": [
    {
      "epreuve": {"id": 157, "titre": "IA L3", ...},
      "score": 4.8,
      "reason": "Similaire Ã  vos Ã©preuves prÃ©fÃ©rÃ©es"
    },
    ...
  ]
}
```

---

## ğŸ”¬ Pour Aller Plus Loin

### Articles de Recherche

1. **He et al. (2017)** - "Neural Collaborative Filtering"
   - Article original qui a introduit NCF
   - https://arxiv.org/abs/1708.05031

2. **Koren et al. (2009)** - "Matrix Factorization Techniques"
   - Base thÃ©orique de la factorisation matricielle

### AmÃ©liorations Possibles

1. **Ajouter des Features** :
   - Utiliser le texte des descriptions (NLP)
   - IntÃ©grer l'heure de consultation
   - Prendre en compte les amis/groupes

2. **ModÃ¨les Plus AvancÃ©s** :
   - Transformers (comme BERT)
   - Graph Neural Networks
   - Reinforcement Learning

3. **Optimisations** :
   - Quantization (rÃ©duire la taille du modÃ¨le)
   - Caching des recommandations
   - A/B Testing

---

**CrÃ©Ã© le** : 10 dÃ©cembre 2025  
**Auteur** : SystÃ¨me de Recommandation - Banque d'Ã‰preuves  
**Version** : 1.0
